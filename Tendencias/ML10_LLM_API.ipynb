{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Clase 10: Conexi√≥n a Gemini (Google) v√≠a API**"
      ],
      "metadata": {
        "id": "gDF0nqFgbvis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalaci√≥n de librer√≠as**"
      ],
      "metadata": {
        "id": "BpyoCHygcAow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsXnoPI0bq_l",
        "outputId": "f970971b-b628-4ce5-b98a-a8a449ba70c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.55.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Configuraci√≥n inicial**\n",
        "### **üõ†Ô∏è Configuraci√≥n de tu Entorno de IA: Obtenci√≥n de API Key**\n",
        "\n",
        "Para interactuar con los modelos de lenguaje de √∫ltima generaci√≥n (como Gemini 1.5 Flash) desde Python, necesitamos una \"llave\" que nos identifique ante los servidores de Google. En esta sesi√≥n, utilizaremos el plan gratuito para desarrolladores.\n",
        "\n",
        "**Paso 1: Generar tu API Key**\n",
        "- Accede a [Google AI Studio](https://aistudio.google.com/).\n",
        "\n",
        "- Inicia sesi√≥n con tu cuenta de Google/Gmail.\n",
        "\n",
        "- En el panel lateral izquierdo, haz clic en el bot√≥n \"Get API key\".\n",
        "\n",
        "- Selecciona \"Create API key in new project\".\n",
        "\n",
        "- Copia la clave generada. Mant√©n esta clave en secreto; es personal y est√° vinculada a tu cuenta.\n",
        "\n",
        "**Paso 2: Configurar la clave en Google Colab (Opcional)**\n",
        "\n",
        "Para evitar escribir la clave directamente en el c√≥digo (una mala pr√°ctica de seguridad conocida como hardcoding), usaremos el sistema de \"Secrets\" de Colab:\n",
        "\n",
        "- En la barra lateral izquierda de este notebook, haz clic en el icono de la llave (üîë Secrets).\n",
        "\n",
        "- A√±ade un nuevo secreto con el nombre: GOOGLE_API_KEY.\n",
        "\n",
        "- Pega tu clave en el campo \"Value\".\n",
        "\n",
        "_Importante: Activa el interruptor de \"Notebook access\" para que el c√≥digo pueda leer la clave._"
      ],
      "metadata": {
        "id": "aemQnaKTcRiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "# Recuperar la clave desde los secretos de Colab\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    print(\"‚úÖ Configuraci√≥n exitosa: API Key cargada correctamente.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error: No se encontr√≥ la clave 'GOOGLE_API_KEY' en los secretos de Colab.\")\n",
        "    print(\"Por favor, revisa la gu√≠a anterior o establecela a continuaci√≥n\")\n",
        "api_key_hard = None #Se puede configurar directamente aqu√≠\n",
        "if api_key_hard is not None and api_key is None:\n",
        "    api_key = api_key_hard\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    print(\"‚úÖ Configuraci√≥n exitosa: API Key cargada correctamente.\")\n",
        "elif api_key_hard is not None and api_key is not None:\n",
        "    print(\"‚ùå Error: No se encontr√≥ la clave 'GOOGLE_API_KEY' en los secretos de Colab ni en la variable 'api_key_hard'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKTbSqRKcxGq",
        "outputId": "2821805d-6b81-4a9c-b61d-240db33e4a70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuraci√≥n exitosa: API Key cargada correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Viendo modelos disponibles en Gemini**"
      ],
      "metadata": {
        "id": "2y37Wm1seUQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"List of models that support generateContent:\\n\")\n",
        "for m in client.models.list():\n",
        "    for action in m.supported_actions:\n",
        "        if action == \"generateContent\":\n",
        "            print(m.name)\n",
        "print(60*\"-\")\n",
        "\n",
        "print(\"List of models that support embedContent:\\n\")\n",
        "for m in client.models.list():\n",
        "    for action in m.supported_actions:\n",
        "        if action == \"embedContent\":\n",
        "            print(m.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImOtDeXAb2WU",
        "outputId": "03ad9865-2a28-45a5-ec91-b5b03540166e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of models that support generateContent:\n",
            "\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n",
            "------------------------------------------------------------\n",
            "List of models that support embedContent:\n",
            "\n",
            "models/gemini-embedding-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En Business Analytics, usamos generateContent para el Front-end (hablar con el cliente) y embedContent para el Back-end (encontrar el albar√°n correcto en una base de datos de 1 mill√≥n).\n",
        "\n",
        "- **A. generateContent: El modelo \"Hablador\".**\n",
        "\n",
        "Este es el que usas para el triaje de tickets que vimos en otra Sesi√≥n. Recibe un texto y genera una respuesta basada en su entrenamiento.\n",
        "\n",
        "Ejemplo de uso: \"Resume este ticket de soporte y dime si el cliente est√° enfadado\".\n",
        "\n",
        "- B. **embedContent: El modelo \"Matem√°tico\"**\n",
        "\n",
        "Este modelo convierte el texto en un Vector (un punto en un mapa de miles de dimensiones).\n",
        "\n",
        "Si dos frases tienen vectores cercanos, es que significan lo mismo, aunque usen palabras distintas.\n",
        "\n",
        "Ejemplo de negocio: Si un cliente busca \"mi paquete no llega\" y otro busca \"retraso en el env√≠o\", los embeddings detectar√°n que ambos puntos est√°n en la misma zona del mapa."
      ],
      "metadata": {
        "id": "3pcJt9NwfNRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"Explain how AI works in a few words\",\n",
        ")\n",
        "\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "RAOHhYceeSUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e81ba4-bf1c-4f9d-f5f5-348cbc343671"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI learns **patterns from data** to make **predictions** or decisions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los modelos de Gemini suelen tener habilitada la \"reflexi√≥n\" de forma predeterminada, lo que permite que el modelo razone antes de responder a una solicitud.\n",
        "\n",
        "Cada modelo admite diferentes configuraciones de pensamiento, lo que te brinda control sobre el costo, la latencia y la inteligencia."
      ],
      "metadata": {
        "id": "bgq6wwSBjz_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"How does AI work?\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_level=\"low\")\n",
        "    ),\n",
        ")\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "hPekcj1Bj0-h",
        "outputId": "9059c956-2188-4954-bab4-a2d8f4c92b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "At its simplest level, Artificial Intelligence (AI) does not \"think\" the way a human does. Instead, it **finds patterns in massive amounts of data** and uses those patterns to make predictions or decisions.\n\nHere is a breakdown of how it works, from the basic building blocks to the complex systems we see today.\n\n---\n\n### 1. The Core Ingredients: Data and Algorithms\nTo build an AI, you need two main things:\n*   **Data:** This is the \"fuel.\" It can be text, images, sensor readings, or numbers. For example, to teach an AI to recognize a cat, you show it millions of photos of cats.\n*   **Algorithms:** These are the \"engines.\" An algorithm is a set of mathematical rules or instructions that tells the computer how to analyze the data.\n\n### 2. Machine Learning (The \"Learning\" Part)\nTraditional computer programs follow \"If-Then\" logic (e.g., *If the user clicks this button, then open this file*). \n\n**Machine Learning** is different. Instead of a human writing every rule, we give the computer an algorithm and a lot of data, and the computer **writes its own rules.** \n*   **Training:** You feed the system data (like chess games). It tries to predict the next move.\n*   **Feedback:** If it gets it wrong, the algorithm adjusts its internal math to do better next time.\n*   **Inference:** Once trained, you give it a new problem it has never seen before, and it uses its \"experience\" to provide an answer.\n\n### 3. Neural Networks (The Structure)\nModern AI (like ChatGPT or Midjourney) uses a specific type of machine learning called **Deep Learning**, which is inspired by the human brain.\n*   It consists of layers of \"neurons\" (mathematical functions).\n*   Data enters the first layer, is processed, and passes to the next.\n*   Each layer looks for something specific. In image recognition, the first layer might find lines, the second layer finds shapes (circles), and the third finds features (eyes or ears).\n\n### 4. How Modern AI (like ChatGPT) Works\nThe AI you interact with today is usually a **Large Language Model (LLM)**. It works on the principle of **probability.**\n*   When you ask ChatGPT a question, it isn‚Äôt \"looking up\" the answer in a database.\n*   It is calculating, word by word, what the most likely next word should be based on all the text it has ever read. \n*   *Example:* If you type \"The cat sat on the...\", the AI‚Äôs math tells it there is an 80% chance the next word is \"mat\" and a 1% chance it is \"refrigerator.\"\n\n### 5. The Three Main Types of Learning\nHow do we actually get the AI to learn the data?\n1.  **Supervised Learning:** Like a student with a teacher. You give the AI \"labeled\" data (e.g., a photo labeled \"Dog\"). It learns to associate the label with the image.\n2.  **Unsupervised Learning:** The AI is given raw data and told to find its own patterns. (e.g., \"Look at these 1 million customers and group them into five types based on their shopping habits.\")\n3.  **Reinforcement Learning:** Like training a dog with treats. The AI performs a task, and if it does it well, it gets a \"point.\" If it fails, it loses a point. This is how AI learns to play video games or drive cars.\n\n### 6. What AI is NOT\n*   **It isn't conscious:** It doesn't have feelings, beliefs, or desires. It is a very sophisticated calculator.\n*   **It doesn't \"know\" facts:** It knows *patterns*. This is why AI sometimes \"hallucinates\" (confidently states things that are false)‚Äîit is simply following a mathematical pattern that looks correct but isn't grounded in reality.\n\n### Summary\nAI works by **taking in massive amounts of data**, using **math (algorithms)** to identify patterns in that data, and then **applying those patterns** to new situations to solve problems, generate text, or recognize objects."
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes guiar el comportamiento de los modelos de Gemini con instrucciones del sistema. Para ello, pasa un objeto GenerateContentConfig."
      ],
      "metadata": {
        "id": "01zD02dJkoMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
        "    contents=\"Hello there\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "JtWwYRFSj-QB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "46b56e3d-2444-43cc-ca1b-18932a3d4bae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Markdown' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3314158626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Markdown' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objeto GenerateContentConfig tambi√©n te permite reconfigurar los par√°metros de generaci√≥n predeterminados, como la temperatura."
      ],
      "metadata": {
        "id": "3IhUrE_NlEU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=[\"Explain how AI works\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.1\n",
        "    )\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "55fms_KRlFUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La API de Gemini admite entradas multimodales, lo que te permite combinar texto con archivos multimedia. En el siguiente ejemplo, se muestra c√≥mo proporcionar una imagen:"
      ],
      "metadata": {
        "id": "Mh_rbSqYlm6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/content/alb1.png\")\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=[image, \"Tell me about this document\"]\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "kbStinjgloRc",
        "outputId": "e9d2b229-8fc1-48c3-9b45-c1e4755ac48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This document is a Spanish **\"Albar√°n\"**, which translates to a **delivery note** or **delivery slip**. It details a set of services and charges related to the rental or purchase of a commercial space.\n\nHere is a breakdown of the key information:\n\n### **Parties Involved**\n*   **Issuer (Seller/Provider):** Jos√© L√≥pez, based in Spain.\n*   **Recipient (Client):** Luisa Fernandez, located at Avd. Del Prado in Madrid, Spain.\n*   **Note:** Both parties share the same placeholder tax ID (NIF: 12345678Z), suggesting this is a template or sample document.\n\n### **Document Details**\n*   **Document Number:** AL-2020-0002\n*   **Date:** January 2, 2020\n\n### **Listed Items & Costs**\nThe document lists four items, all with a 5% discount applied to the base price:\n1.  **Alquiler local (Local rent):** ‚Ç¨522.50\n2.  **Dep√≥sito para comprar local o negocio (Deposit to buy local/business):** ‚Ç¨997.50\n3.  **Dep√≥sito/Garant√≠a 3 meses (3-month security deposit):** ‚Ç¨1,425.00\n4.  **Derecho a llave (Key money/Goodwill):** ‚Ç¨142.50\n\n### **Financial Summary**\n*   **Total Taxable Base (Base Imponible):** ‚Ç¨3,087.50\n*   **VAT (I.V.A.) at 21%:** ‚Ç¨648.39\n*   **Withholding Tax (Retenci√≥n) at 19%:** -‚Ç¨586.63 (This is common in Spanish commercial rentals where the tenant pays part of the tax directly to the government on behalf of the landlord).\n*   **GRAND TOTAL:** **‚Ç¨3,149.26**\n\nWhile the document is titled \"Albar√°n,\" it contains detailed tax calculations (IVA and Retenci√≥n) that are typically found on a final invoice (\"Factura\")."
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VvNvcGsFmMui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}