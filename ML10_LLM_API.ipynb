{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Clase 10: Conexión a Gemini (Google) vía API**"
      ],
      "metadata": {
        "id": "gDF0nqFgbvis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalación de librerías**"
      ],
      "metadata": {
        "id": "BpyoCHygcAow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsXnoPI0bq_l",
        "outputId": "06880b2d-39b2-4a17-d189-14a2200d8218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.55.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Configuración inicial**"
      ],
      "metadata": {
        "id": "aemQnaKTcRiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "api_key = \"TU_API_KEY_AQUÍ\"\n",
        "client = genai.Client(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKTbSqRKcxGq",
        "outputId": "51b25ea8-0a88-4572-84ff-93c4b15c1945"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI finds patterns in data to make predictions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Viendo modelos disponibles en Gemini**"
      ],
      "metadata": {
        "id": "2y37Wm1seUQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"List of models that support generateContent:\\n\")\n",
        "for m in client.models.list():\n",
        "    for action in m.supported_actions:\n",
        "        if action == \"generateContent\":\n",
        "            print(m.name)\n",
        "print(60*\"-\")\n",
        "\n",
        "print(\"List of models that support embedContent:\\n\")\n",
        "for m in client.models.list():\n",
        "    for action in m.supported_actions:\n",
        "        if action == \"embedContent\":\n",
        "            print(m.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImOtDeXAb2WU",
        "outputId": "9fdd038c-746a-4a25-8703-37922da103ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of models that support generateContent:\n",
            "\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n",
            "------------------------------------------------------------\n",
            "List of models that support embedContent:\n",
            "\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En Business Analytics, usamos generateContent para el Front-end (hablar con el cliente) y embedContent para el Back-end (encontrar el albarán correcto en una base de datos de 1 millón).\n",
        "\n",
        "- **A. generateContent: El modelo \"Hablador\".**\n",
        "\n",
        "Este es el que usas para el triaje de tickets que vimos en otra Sesión. Recibe un texto y genera una respuesta basada en su entrenamiento.\n",
        "\n",
        "Ejemplo de uso: \"Resume este ticket de soporte y dime si el cliente está enfadado\".\n",
        "\n",
        "- B. **embedContent: El modelo \"Matemático\"**\n",
        "\n",
        "Este modelo convierte el texto en un Vector (un punto en un mapa de miles de dimensiones).\n",
        "\n",
        "Si dos frases tienen vectores cercanos, es que significan lo mismo, aunque usen palabras distintas.\n",
        "\n",
        "Ejemplo de negocio: Si un cliente busca \"mi paquete no llega\" y otro busca \"retraso en el envío\", los embeddings detectarán que ambos puntos están en la misma zona del mapa."
      ],
      "metadata": {
        "id": "3pcJt9NwfNRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"Explain how AI works in a few words\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "RAOHhYceeSUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los modelos de Gemini suelen tener habilitada la \"reflexión\" de forma predeterminada, lo que permite que el modelo razone antes de responder a una solicitud.\n",
        "\n",
        "Cada modelo admite diferentes configuraciones de pensamiento, lo que te brinda control sobre el costo, la latencia y la inteligencia."
      ],
      "metadata": {
        "id": "bgq6wwSBjz_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"How does AI work?\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_level=\"low\")\n",
        "    ),\n",
        ")\n",
        "#Convirtiendo a Markdown\n",
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "hPekcj1Bj0-h",
        "outputId": "9059c956-2188-4954-bab4-a2d8f4c92b3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "At its simplest level, Artificial Intelligence (AI) does not \"think\" the way a human does. Instead, it **finds patterns in massive amounts of data** and uses those patterns to make predictions or decisions.\n\nHere is a breakdown of how it works, from the basic building blocks to the complex systems we see today.\n\n---\n\n### 1. The Core Ingredients: Data and Algorithms\nTo build an AI, you need two main things:\n*   **Data:** This is the \"fuel.\" It can be text, images, sensor readings, or numbers. For example, to teach an AI to recognize a cat, you show it millions of photos of cats.\n*   **Algorithms:** These are the \"engines.\" An algorithm is a set of mathematical rules or instructions that tells the computer how to analyze the data.\n\n### 2. Machine Learning (The \"Learning\" Part)\nTraditional computer programs follow \"If-Then\" logic (e.g., *If the user clicks this button, then open this file*). \n\n**Machine Learning** is different. Instead of a human writing every rule, we give the computer an algorithm and a lot of data, and the computer **writes its own rules.** \n*   **Training:** You feed the system data (like chess games). It tries to predict the next move.\n*   **Feedback:** If it gets it wrong, the algorithm adjusts its internal math to do better next time.\n*   **Inference:** Once trained, you give it a new problem it has never seen before, and it uses its \"experience\" to provide an answer.\n\n### 3. Neural Networks (The Structure)\nModern AI (like ChatGPT or Midjourney) uses a specific type of machine learning called **Deep Learning**, which is inspired by the human brain.\n*   It consists of layers of \"neurons\" (mathematical functions).\n*   Data enters the first layer, is processed, and passes to the next.\n*   Each layer looks for something specific. In image recognition, the first layer might find lines, the second layer finds shapes (circles), and the third finds features (eyes or ears).\n\n### 4. How Modern AI (like ChatGPT) Works\nThe AI you interact with today is usually a **Large Language Model (LLM)**. It works on the principle of **probability.**\n*   When you ask ChatGPT a question, it isn’t \"looking up\" the answer in a database.\n*   It is calculating, word by word, what the most likely next word should be based on all the text it has ever read. \n*   *Example:* If you type \"The cat sat on the...\", the AI’s math tells it there is an 80% chance the next word is \"mat\" and a 1% chance it is \"refrigerator.\"\n\n### 5. The Three Main Types of Learning\nHow do we actually get the AI to learn the data?\n1.  **Supervised Learning:** Like a student with a teacher. You give the AI \"labeled\" data (e.g., a photo labeled \"Dog\"). It learns to associate the label with the image.\n2.  **Unsupervised Learning:** The AI is given raw data and told to find its own patterns. (e.g., \"Look at these 1 million customers and group them into five types based on their shopping habits.\")\n3.  **Reinforcement Learning:** Like training a dog with treats. The AI performs a task, and if it does it well, it gets a \"point.\" If it fails, it loses a point. This is how AI learns to play video games or drive cars.\n\n### 6. What AI is NOT\n*   **It isn't conscious:** It doesn't have feelings, beliefs, or desires. It is a very sophisticated calculator.\n*   **It doesn't \"know\" facts:** It knows *patterns*. This is why AI sometimes \"hallucinates\" (confidently states things that are false)—it is simply following a mathematical pattern that looks correct but isn't grounded in reality.\n\n### Summary\nAI works by **taking in massive amounts of data**, using **math (algorithms)** to identify patterns in that data, and then **applying those patterns** to new situations to solve problems, generate text, or recognize objects."
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes guiar el comportamiento de los modelos de Gemini con instrucciones del sistema. Para ello, pasa un objeto GenerateContentConfig."
      ],
      "metadata": {
        "id": "01zD02dJkoMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
        "    contents=\"Hello there\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "JtWwYRFSj-QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objeto GenerateContentConfig también te permite reconfigurar los parámetros de generación predeterminados, como la temperatura."
      ],
      "metadata": {
        "id": "3IhUrE_NlEU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=[\"Explain how AI works\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.1\n",
        "    )\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "55fms_KRlFUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La API de Gemini admite entradas multimodales, lo que te permite combinar texto con archivos multimedia. En el siguiente ejemplo, se muestra cómo proporcionar una imagen:"
      ],
      "metadata": {
        "id": "Mh_rbSqYlm6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/content/alb1.png\")\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=[image, \"Tell me about this document\"]\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "kbStinjgloRc",
        "outputId": "e9d2b229-8fc1-48c3-9b45-c1e4755ac48c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This document is a Spanish **\"Albarán\"**, which translates to a **delivery note** or **delivery slip**. It details a set of services and charges related to the rental or purchase of a commercial space.\n\nHere is a breakdown of the key information:\n\n### **Parties Involved**\n*   **Issuer (Seller/Provider):** José López, based in Spain.\n*   **Recipient (Client):** Luisa Fernandez, located at Avd. Del Prado in Madrid, Spain.\n*   **Note:** Both parties share the same placeholder tax ID (NIF: 12345678Z), suggesting this is a template or sample document.\n\n### **Document Details**\n*   **Document Number:** AL-2020-0002\n*   **Date:** January 2, 2020\n\n### **Listed Items & Costs**\nThe document lists four items, all with a 5% discount applied to the base price:\n1.  **Alquiler local (Local rent):** €522.50\n2.  **Depósito para comprar local o negocio (Deposit to buy local/business):** €997.50\n3.  **Depósito/Garantía 3 meses (3-month security deposit):** €1,425.00\n4.  **Derecho a llave (Key money/Goodwill):** €142.50\n\n### **Financial Summary**\n*   **Total Taxable Base (Base Imponible):** €3,087.50\n*   **VAT (I.V.A.) at 21%:** €648.39\n*   **Withholding Tax (Retención) at 19%:** -€586.63 (This is common in Spanish commercial rentals where the tenant pays part of the tax directly to the government on behalf of the landlord).\n*   **GRAND TOTAL:** **€3,149.26**\n\nWhile the document is titled \"Albarán,\" it contains detailed tax calculations (IVA and Retención) that are typically found on a final invoice (\"Factura\")."
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VvNvcGsFmMui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}